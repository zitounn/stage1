{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_augmentation(image, mask):\n",
    "    \"\"\"Returns (maybe) augmented images\n",
    "\n",
    "    (1) Random flip (left <--> right)\n",
    "    (2) Random flip (up <--> down)\n",
    "    (3) Random brightness\n",
    "    (4) Random hue\n",
    "\n",
    "    Args:\n",
    "        image (3-D Tensor): Image tensor of (H, W, C)\n",
    "        mask (3-D Tensor): Mask image tensor of (H, W, 1)\n",
    "\n",
    "    Returns:\n",
    "        image: Maybe augmented image (same shape as input `image`)\n",
    "        mask: Maybe augmented mask (same shape as input `mask`)\n",
    "    \"\"\"\n",
    "    concat_image = tf.concat([image, mask], axis=-1)\n",
    "\n",
    "    maybe_flipped = tf.image.random_flip_left_right(concat_image)\n",
    "    maybe_flipped = tf.image.random_flip_up_down(concat_image)\n",
    "\n",
    "    image = maybe_flipped[:, :, :-1]\n",
    "    mask = maybe_flipped[:, :, -1:]\n",
    "\n",
    "    image = tf.image.random_brightness(image, 0.7)\n",
    "    image = tf.image.random_hue(image, 0.3)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_image_mask(queue, folder_path = 'train_data_processed/'):\n",
    "    \"\"\"Returns `image` and `mask`\n",
    "\n",
    "    Input pipeline:\n",
    "        Queue -> CSV -> FileRead -> Decode JPEG\n",
    "\n",
    "    (1) Queue contains a CSV filename\n",
    "    (2) Text Reader opens the CSV\n",
    "        CSV file contains two columns\n",
    "        [\"path/to/image.jpg\", \"path/to/mask.jpg\"]\n",
    "    (3) File Reader opens both files\n",
    "    (4) Decode JPEG to tensors\n",
    "\n",
    "    Notes:\n",
    "        height, width = 640, 960\n",
    "\n",
    "    Returns\n",
    "        image (3-D Tensor): (640, 960, 3)\n",
    "        mask (3-D Tensor): (640, 960, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    dw = 2\n",
    "    size = int(1024/dw)\n",
    "    \n",
    "    text_reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    _, csv_content = text_reader.read(queue)\n",
    "\n",
    "    image_path, mask_path = tf.decode_csv(\n",
    "        csv_content, record_defaults=[[\"\"], [\"\"]])\n",
    "        \n",
    "    image_path = folder_path + image_path\n",
    "    mask_path = folder_path + mask_path\n",
    "\n",
    "    image_file = tf.read_file(image_path)\n",
    "    mask_file = tf.read_file(mask_path)\n",
    "\n",
    "    image = tf.image.decode_jpeg(image_file, channels=1)\n",
    "    image.set_shape([1024, 1024, 1])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize_images(image,(size,size))\n",
    "\n",
    "    mask = tf.image.decode_jpeg(mask_file, channels=1)\n",
    "    mask.set_shape([1024, 1024, 1])\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = mask / (tf.reduce_max(mask) + 1e-7)\n",
    "    mask = tf.image.resize_images(mask,(size,size))\n",
    "\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dw=2\n",
    "\n",
    "flags_batch_size = 4\n",
    "\n",
    "\n",
    "train_csv = tf.train.string_input_producer(['train.csv'])\n",
    "test_csv = tf.train.string_input_producer(['test.csv'])\n",
    "train_image, train_mask = get_image_mask(train_csv, folder_path = 'train_data_processed/' )\n",
    "test_image, test_mask = get_image_mask(test_csv, folder_path = 'test_data_processed/' )\n",
    "\n",
    "\n",
    "X_batch_op, y_batch_op = tf.train.shuffle_batch(\n",
    "        [train_image, train_mask],\n",
    "        batch_size=flags_batch_size,\n",
    "        capacity=flags_batch_size * 5,\n",
    "        min_after_dequeue=flags_batch_size * 2,\n",
    "        allow_smaller_final_batch=True,)\n",
    "\n",
    "X_test_op, y_test_op = tf.train.batch(\n",
    "        [test_image, test_mask],\n",
    "        batch_size=flags_batch_size,\n",
    "        capacity=flags_batch_size * 2,\n",
    "        allow_smaller_final_batch=True,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_8/input_producer_8_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer_8, input_producer_8/Const, ^input_producer_8/Assert/Assert)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    \n",
    "    #X_batch, y_batch = sess.run([X_batch_op, y_batch_op])\n",
    "    te = sess.run(X_batch_op)\n",
    "    \n",
    "    te.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import pandas as pd \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "test_data_processed/JPCLN001.jpg; No such file or directory\n\t [[Node: ReadFile = ReadFile[](add)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[512,512,1], [512,512,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: test_data_processed/JPCLN001.jpg; No such file or directory\n\t [[Node: ReadFile = ReadFile[](add)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[512,512,1], [512,512,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a3e2211a3bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#sess.run(init_var)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/mlpy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: test_data_processed/JPCLN001.jpg; No such file or directory\n\t [[Node: ReadFile = ReadFile[](add)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[512,512,1], [512,512,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_processing(csv_file):\n",
    "    \"\"\"\n",
    "    Function that reads the csv function, shuffles it and shapes it into\n",
    "    a matrix suitable for tensorflow dataframe. Return dataset with\n",
    "    filename in the postiion of the images.\n",
    "    \"\"\"\n",
    "    pd_frame = pd.DataFrame.from_csv(csv_file, header=None, index_col=None)\n",
    "\n",
    "    input_file = pd_frame[0].tolist()\n",
    "    mask_file = pd_frame[1].tolist()\n",
    "    \n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((input_file, mask_file))\n",
    "\n",
    "\n",
    "    return (tf_dataset)\n",
    "    \n",
    "\n",
    "def _parser_function(input_file, mask_file):\n",
    "    \n",
    "    image_path = 'test_data_processed/' + input_file\n",
    "    mask_path = 'test_data_processed/' + mask_file\n",
    "\n",
    "    dw = 2\n",
    "    size = int(1024/dw)\n",
    "\n",
    "    image_file = tf.read_file(image_path)\n",
    "    mask_file = tf.read_file(mask_path)\n",
    "\n",
    "    image = tf.image.decode_jpeg(image_file, channels=1)\n",
    "    image.set_shape([1024, 1024, 1])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize_images(image,(size,size))\n",
    "    \n",
    "    mask = tf.image.decode_jpeg(mask_file, channels=1)\n",
    "    mask.set_shape([1024, 1024, 1])\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = mask / (tf.reduce_max(mask) + 1e-7)\n",
    "    mask = tf.image.resize_images(\n",
    "        mask,\n",
    "        (size,size),\n",
    "       )\n",
    "\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "\n",
    "tf_dataset = data_processing('train.csv')\n",
    "\n",
    "tf_dataset_images = tf_dataset.map(_parser_function)\n",
    "\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(tf_dataset_images.output_types, tf_dataset_images.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "data_iterator  = iterator.make_initializer(tf_dataset_images)\n",
    "\n",
    "imag = next_element[0]\n",
    "mask  = next_element[1]\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(data_iterator)\n",
    "\n",
    "    #sess.run(init_var)\n",
    "\n",
    "    dat = sess.run([mask])\n",
    "    print(dat)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mmsek/thesis/xray/testcnn/stage_1/stage1/net2'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_conv_pool(input_,\n",
    "                   n_filters,\n",
    "                   training,\n",
    "                   flags,\n",
    "                   name,\n",
    "                   pool=True,\n",
    "                   activation=tf.nn.relu):\n",
    "    \"\"\"{Conv -> BN -> RELU}x2 -> {Pool, optional}\n",
    "    Args:\n",
    "        input_ (4-D Tensor): (batch_size, H, W, C)\n",
    "        n_filters (list): number of filters [int, int]\n",
    "        training (1-D Tensor): Boolean Tensor\n",
    "        name (str): name postfix\n",
    "        pool (bool): If True, MaxPool2D\n",
    "        activation: Activaion functions\n",
    "    Returns:\n",
    "        net: output of the Convolution operations\n",
    "        pool (optional): output of the max pooling operations\n",
    "    \"\"\"\n",
    "    net = input_\n",
    "\n",
    "    with tf.variable_scope(\"layer{}\".format(name)):\n",
    "        for i, F in enumerate(n_filters):\n",
    "            net = tf.layers.conv2d(\n",
    "                net,\n",
    "                F, (3, 3),\n",
    "                activation=None,\n",
    "                padding='same',\n",
    "                kernel_regularizer=tf.contrib.layers.l2_regularizer(flags.reg),\n",
    "                name=\"conv_{}\".format(i + 1))\n",
    "            net = tf.layers.batch_normalization(\n",
    "                net, training=training, name=\"bn_{}\".format(i + 1))\n",
    "            net = activation(net, name=\"relu{}_{}\".format(name, i + 1))\n",
    "\n",
    "        if pool is False:\n",
    "            return net\n",
    "\n",
    "        pool = tf.layers.max_pooling2d(\n",
    "            net, (2, 2), strides=(2, 2), name=\"pool_{}\".format(name))\n",
    "\n",
    "        return net, pool\n",
    "\n",
    "\n",
    "def upconv_concat(inputA, input_B, n_filter, flags, name):\n",
    "    \"\"\"Upsample `inputA` and concat with `input_B`\n",
    "    Args:\n",
    "        input_A (4-D Tensor): (N, H, W, C)\n",
    "        input_B (4-D Tensor): (N, 2*H, 2*H, C2)\n",
    "        name (str): name of the concat operation\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, 2*H, 2*W, C + C2)\n",
    "    \"\"\"\n",
    "    up_conv = upconv_2D(inputA, n_filter, flags, name)\n",
    "\n",
    "    return tf.concat(\n",
    "        [up_conv, input_B], axis=-1, name=\"concat_{}\".format(name))\n",
    "\n",
    "\n",
    "def upconv_2D(tensor, n_filter, flags, name):\n",
    "    \"\"\"Up Convolution `tensor` by 2 times\n",
    "    Args:\n",
    "        tensor (4-D Tensor): (N, H, W, C)\n",
    "        n_filter (int): Filter Size\n",
    "        name (str): name of upsampling operations\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, 2 * H, 2 * W, C)\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.layers.conv2d_transpose(\n",
    "        tensor,\n",
    "        filters=n_filter,\n",
    "        kernel_size=2,\n",
    "        strides=2,\n",
    "        kernel_regularizer=tf.contrib.layers.l2_regularizer(flags.reg),\n",
    "        name=\"upsample_{}\".format(name))\n",
    "\n",
    "\n",
    "def make_unet(X, training, flags=None):\n",
    "    \"\"\"Build a U-Net architecture\n",
    "    Args:\n",
    "        X (4-D Tensor): (N, H, W, C)\n",
    "        training (1-D Tensor): Boolean Tensor is required for batchnormalization layers\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, H, W, C)\n",
    "            Same shape as the `input` tensor\n",
    "    Notes:\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    net = X / 127.5 - 1\n",
    "    conv1, pool1 = conv_conv_pool(net, [8, 8], training, flags, name=1)\n",
    "    conv2, pool2 = conv_conv_pool(pool1, [16, 16], training, flags, name=2)\n",
    "    conv3, pool3 = conv_conv_pool(pool2, [32, 32], training, flags, name=3)\n",
    "    conv4, pool4 = conv_conv_pool(pool3, [64, 64], training, flags, name=4)\n",
    "    conv5 = conv_conv_pool(\n",
    "        pool4, [128, 128], training, flags, name=5, pool=False)\n",
    "\n",
    "    up6 = upconv_concat(conv5, conv4, 64, flags, name=6)\n",
    "    conv6 = conv_conv_pool(up6, [64, 64], training, flags, name=6, pool=False)\n",
    "\n",
    "    up7 = upconv_concat(conv6, conv3, 32, flags, name=7)\n",
    "    conv7 = conv_conv_pool(up7, [32, 32], training, flags, name=7, pool=False)\n",
    "\n",
    "    up8 = upconv_concat(conv7, conv2, 16, flags, name=8)\n",
    "    conv8 = conv_conv_pool(up8, [16, 16], training, flags, name=8, pool=False)\n",
    "\n",
    "    up9 = upconv_concat(conv8, conv1, 8, flags, name=9)\n",
    "    conv9 = conv_conv_pool(up9, [8, 8], training, flags, name=9, pool=False)\n",
    "\n",
    "    return tf.layers.conv2d(\n",
    "        conv9,\n",
    "        1, (1, 1),\n",
    "        name='final',\n",
    "        activation=tf.nn.sigmoid,\n",
    "        padding='same')\n",
    "\n",
    "\n",
    "def IOU_(y_pred, y_true):\n",
    "    \"\"\"Returns a (approx) IOU score\n",
    "    intesection = y_pred.flatten() * y_true.flatten()\n",
    "    Then, IOU = 2 * intersection / (y_pred.sum() + y_true.sum() + 1e-7) + 1e-7\n",
    "    Args:\n",
    "        y_pred (4-D array): (N, H, W, 1)\n",
    "        y_true (4-D array): (N, H, W, 1)\n",
    "    Returns:\n",
    "        float: IOU score\n",
    "    \"\"\"\n",
    "    H, W, _ = y_pred.get_shape().as_list()[1:]\n",
    "\n",
    "    pred_flat = tf.reshape(y_pred, [-1, H * W])\n",
    "    true_flat = tf.reshape(y_true, [-1, H * W])\n",
    "\n",
    "    intersection = 2 * tf.reduce_sum(pred_flat * true_flat, axis=1) + 1e-7\n",
    "    denominator = tf.reduce_sum(\n",
    "        pred_flat, axis=1) + tf.reduce_sum(\n",
    "            true_flat, axis=1) + 1e-7\n",
    "\n",
    "    return tf.reduce_mean(intersection / denominator)\n",
    "\n",
    "\n",
    "def make_train_op(y_pred, y_true):\n",
    "    \"\"\"Returns a training operation\n",
    "    Loss function = - IOU(y_pred, y_true)\n",
    "    IOU is\n",
    "        (the area of intersection)\n",
    "        --------------------------\n",
    "        (the area of two boxes)\n",
    "    Args:\n",
    "        y_pred (4-D Tensor): (N, H, W, 1)\n",
    "        y_true (4-D Tensor): (N, H, W, 1)\n",
    "    Returns:\n",
    "        train_op: minimize operation\n",
    "    \"\"\"\n",
    "    loss = -IOU_(y_pred, y_true)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    optim = tf.train.AdamOptimizer()\n",
    "    return optim.minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "def read_flags():\n",
    "    \"\"\"Returns flags\"\"\"\n",
    "\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        \"--epochs\", default=1, type=int, help=\"Number of epochs\")\n",
    "\n",
    "    parser.add_argument(\"--batch-size\", default=4, type=int, help=\"Batch size\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--logdir\", default=\"logdir\", help=\"Tensorboard log directory\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--reg\", type=float, default=0.1, help=\"L2 Regularizer Term\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--ckdir\", default=\"models\", help=\"Checkpoint directory\")\n",
    "\n",
    "    flags = parser.parse_args()\n",
    "    return flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 512, 512, 1), (?, 512, 512, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 512, 512, 1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def conv_conv_pool(input_,\n",
    "                   n_filters,\n",
    "                   training,\n",
    "                   flags,\n",
    "                   name,\n",
    "                   pool=True,\n",
    "                   activation=tf.nn.relu):\n",
    "    \"\"\"{Conv -> BN -> RELU}x2 -> {Pool, optional}\n",
    "    Args:\n",
    "        input_ (4-D Tensor): (batch_size, H, W, C)\n",
    "        n_filters (list): number of filters [int, int]\n",
    "        training (1-D Tensor): Boolean Tensor\n",
    "        name (str): name postfix\n",
    "        pool (bool): If True, MaxPool2D\n",
    "        activation: Activaion functions\n",
    "    Returns:\n",
    "        net: output of the Convolution operations\n",
    "        pool (optional): output of the max pooling operations\n",
    "    \"\"\"\n",
    "    net = input_\n",
    "\n",
    "    with tf.variable_scope(\"layer{}\".format(name)):\n",
    "        for i, F in enumerate(n_filters):\n",
    "            net = tf.layers.conv2d(\n",
    "                net,\n",
    "                F, (3, 3),\n",
    "                activation=None,\n",
    "                padding='same',\n",
    "                kernel_regularizer=tf.contrib.layers.l2_regularizer(flags.reg),\n",
    "                name=\"conv_{}\".format(i + 1))\n",
    "            net = tf.layers.batch_normalization(\n",
    "                net, training=training, name=\"bn_{}\".format(i + 1))\n",
    "            net = activation(net, name=\"relu{}_{}\".format(name, i + 1))\n",
    "\n",
    "        if pool is False:\n",
    "            return net\n",
    "\n",
    "        pool = tf.layers.max_pooling2d(\n",
    "            net, (2, 2), strides=(2, 2), name=\"pool_{}\".format(name))\n",
    "\n",
    "        return net, pool\n",
    "\n",
    "\n",
    "def upconv_concat(inputA, input_B, n_filter, flags, name):\n",
    "    \"\"\"Upsample `inputA` and concat with `input_B`\n",
    "    Args:\n",
    "        input_A (4-D Tensor): (N, H, W, C)\n",
    "        input_B (4-D Tensor): (N, 2*H, 2*H, C2)\n",
    "        name (str): name of the concat operation\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, 2*H, 2*W, C + C2)\n",
    "    \"\"\"\n",
    "    up_conv = upconv_2D(inputA, n_filter, flags, name)\n",
    "\n",
    "    return tf.concat(\n",
    "        [up_conv, input_B], axis=-1, name=\"concat_{}\".format(name))\n",
    "\n",
    "\n",
    "def upconv_2D(tensor, n_filter, flags, name):\n",
    "    \"\"\"Up Convolution `tensor` by 2 times\n",
    "    Args:\n",
    "        tensor (4-D Tensor): (N, H, W, C)\n",
    "        n_filter (int): Filter Size\n",
    "        name (str): name of upsampling operations\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, 2 * H, 2 * W, C)\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.layers.conv2d_transpose(\n",
    "        tensor,\n",
    "        filters=n_filter,\n",
    "        kernel_size=2,\n",
    "        strides=2,\n",
    "        kernel_regularizer=tf.contrib.layers.l2_regularizer(flags.reg),\n",
    "        name=\"upsample_{}\".format(name))\n",
    "\n",
    "\n",
    "def make_unet(X, training, flags=None):\n",
    "    \"\"\"Build a U-Net architecture\n",
    "    Args:\n",
    "        X (4-D Tensor): (N, H, W, C)\n",
    "        training (1-D Tensor): Boolean Tensor is required for batchnormalization layers\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, H, W, C)\n",
    "            Same shape as the `input` tensor\n",
    "    Notes:\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    net = X / 127.5 - 1\n",
    "    conv1, pool1 = conv_conv_pool(net, [8, 8], training, flags, name=1)\n",
    "    conv2, pool2 = conv_conv_pool(pool1, [16, 16], training, flags, name=2)\n",
    "    conv3, pool3 = conv_conv_pool(pool2, [32, 32], training, flags, name=3)\n",
    "    conv4, pool4 = conv_conv_pool(pool3, [64, 64], training, flags, name=4)\n",
    "    conv5 = conv_conv_pool(\n",
    "        pool4, [128, 128], training, flags, name=5, pool=False)\n",
    "\n",
    "    up6 = upconv_concat(conv5, conv4, 64, flags, name=6)\n",
    "    conv6 = conv_conv_pool(up6, [64, 64], training, flags, name=6, pool=False)\n",
    "\n",
    "    up7 = upconv_concat(conv6, conv3, 32, flags, name=7)\n",
    "    conv7 = conv_conv_pool(up7, [32, 32], training, flags, name=7, pool=False)\n",
    "\n",
    "    up8 = upconv_concat(conv7, conv2, 16, flags, name=8)\n",
    "    conv8 = conv_conv_pool(up8, [16, 16], training, flags, name=8, pool=False)\n",
    "\n",
    "    up9 = upconv_concat(conv8, conv1, 8, flags, name=9)\n",
    "    conv9 = conv_conv_pool(up9, [8, 8], training, flags, name=9, pool=False)\n",
    "\n",
    "    return tf.layers.conv2d(\n",
    "        conv9,\n",
    "        1, (1, 1),\n",
    "        name='final',\n",
    "        activation=tf.nn.sigmoid,\n",
    "        padding='same')\n",
    "\n",
    "\n",
    "def IOU_(y_pred, y_true):\n",
    "    \"\"\"Returns a (approx) IOU score\n",
    "    intesection = y_pred.flatten() * y_true.flatten()\n",
    "    Then, IOU = 2 * intersection / (y_pred.sum() + y_true.sum() + 1e-7) + 1e-7\n",
    "    Args:\n",
    "        y_pred (4-D array): (N, H, W, 1)\n",
    "        y_true (4-D array): (N, H, W, 1)\n",
    "    Returns:\n",
    "        float: IOU score\n",
    "    \"\"\"\n",
    "    H, W, _ = y_pred.get_shape().as_list()[1:]\n",
    "\n",
    "    pred_flat = tf.reshape(y_pred, [-1, H * W])\n",
    "    true_flat = tf.reshape(y_true, [-1, H * W])\n",
    "\n",
    "    intersection = 2 * tf.reduce_sum(pred_flat * true_flat, axis=1) + 1e-7\n",
    "    denominator = tf.reduce_sum(\n",
    "        pred_flat, axis=1) + tf.reduce_sum(\n",
    "            true_flat, axis=1) + 1e-7\n",
    "\n",
    "    return tf.reduce_mean(intersection / denominator)\n",
    "\n",
    "\n",
    "def make_train_op(y_pred, y_true):\n",
    "    \"\"\"Returns a training operation\n",
    "    Loss function = - IOU(y_pred, y_true)\n",
    "    IOU is\n",
    "        (the area of intersection)\n",
    "        --------------------------\n",
    "        (the area of two boxes)\n",
    "    Args:\n",
    "        y_pred (4-D Tensor): (N, H, W, 1)\n",
    "        y_true (4-D Tensor): (N, H, W, 1)\n",
    "    Returns:\n",
    "        train_op: minimize operation\n",
    "    \"\"\"\n",
    "    loss = -IOU_(y_pred, y_true)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    optim = tf.train.AdamOptimizer()\n",
    "    return optim.minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "def read_flags():\n",
    "    \"\"\"Returns flags\"\"\"\n",
    "\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        \"--epochs\", default=1, type=int, help=\"Number of epochs\")\n",
    "\n",
    "    parser.add_argument(\"--batch-size\", default=4, type=int, help=\"Batch size\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--logdir\", default=\"logdir\", help=\"Tensorboard log directory\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--reg\", type=float, default=0.1, help=\"L2 Regularizer Term\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--ckdir\", default=\"models\", help=\"Checkpoint directory\")\n",
    "\n",
    "    flags = parser.parse_args()\n",
    "    return flags\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_processing(csv_file):\n",
    "    \"\"\"\n",
    "    Function that reads the csv function, shuffles it and shapes it into\n",
    "    a matrix suitable for tensorflow dataframe. Return dataset with\n",
    "    filename in the postiion of the images.\n",
    "    \"\"\"\n",
    "    pd_frame = pd.DataFrame.from_csv(csv_file, header=None, index_col=None)\n",
    "\n",
    "    input_file = pd_frame[0].tolist()\n",
    "    mask_file = pd_frame[1].tolist()\n",
    "    \n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((input_file, mask_file))\n",
    "\n",
    "\n",
    "    return (tf_dataset)\n",
    "    \n",
    "\n",
    "def _parser_function(input_file, mask_file):\n",
    "    \n",
    "    image_path = 'train_data_processed/' + input_file\n",
    "    mask_path = 'train_data_processed/' + mask_file\n",
    "\n",
    "    dw = 2\n",
    "    size = int(1024/dw)\n",
    "\n",
    "    image_file = tf.read_file(image_path)\n",
    "    mask_file = tf.read_file(mask_path)\n",
    "\n",
    "    image = tf.image.decode_jpeg(image_file, channels=1)\n",
    "    image.set_shape([1024, 1024, 1])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize_images(image,(size,size))\n",
    "    \n",
    "    mask = tf.image.decode_jpeg(mask_file, channels=1)\n",
    "    mask.set_shape([1024, 1024, 1])\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = mask / (tf.reduce_max(mask) + 1e-7)\n",
    "    mask = tf.image.resize_images(\n",
    "        mask,\n",
    "        (size,size),\n",
    "       )\n",
    "\n",
    "   \n",
    "    return image, mask\n",
    "\n",
    "def _augment(image, mask):\n",
    "      \n",
    "    if random.uniform(0, 1) < 0.5:\n",
    "\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "        \n",
    "    if random.uniform(0, 1) < 0.5:  \n",
    "        image = tf.image.flip_up_down(image)\n",
    "        mask = tf.image.flip_up_down(mask)\n",
    "\n",
    "\n",
    "\n",
    "    image = tf.image.random_brightness(image, random.uniform(0, 0.5))\n",
    "\n",
    "    \n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def main(flags):\n",
    "    aug_n = 5\n",
    "\n",
    "    tf_dataset = data_processing('train.csv')\n",
    "\n",
    "    tf_dataset_no_aug = tf_dataset.map(_parser_function)\n",
    "\n",
    "    tf_dataset_images_augmented = tf_dataset_no_aug\n",
    "    \n",
    "    for n in range(aug_n):\n",
    "        augmented = tf_dataset_no_aug.map(_augment)\n",
    "        tf_dataset_images_augmented = tf_dataset_images_augmented.concatenate(augmented)\n",
    "\n",
    "\n",
    "    tf_dataset_images = tf_dataset_images_augmented\n",
    "\n",
    "    tf_dataset_images = tf_dataset_images.shuffle(500).repeat().batch(4)\n",
    "\n",
    "\n",
    "    iterator = tf.data.Iterator.from_structure(tf_dataset_images.output_types, tf_dataset_images.output_shapes)\n",
    "\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    data_iterator  = iterator.make_initializer(tf_dataset_images)\n",
    "\n",
    "    X = next_element[0]\n",
    "    y  = next_element[1]\n",
    "\n",
    "    \n",
    "    current_time = time.strftime(\"%m/%d/%H/%M/%S\")\n",
    "    train_logdir = os.path.join(flags.logdir, \"train\", current_time)\n",
    "    test_logdir = os.path.join(flags.logdir, \"test\", current_time)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "           \n",
    "    mode = tf.placeholder(tf.bool, name=\"mode\")\n",
    "\n",
    "    pred = make_unet(X, mode, flags)\n",
    "\n",
    "    tf.add_to_collection(\"inputs\", X)\n",
    "    tf.add_to_collection(\"inputs\", mode)\n",
    "    tf.add_to_collection(\"outputs\", pred)\n",
    "\n",
    "    tf.summary.histogram(\"Predicted Mask\", pred)\n",
    "    tf.summary.image(\"Predicted Mask\", pred)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = make_train_op(pred, y)\n",
    "\n",
    "    IOU_op = IOU_(pred, y)\n",
    "    IOU_op = tf.Print(IOU_op, [IOU_op])\n",
    "    tf.summary.scalar(\"IOU\", IOU_op)\n",
    "\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        train_summary_writer = tf.summary.FileWriter(train_logdir, sess.graph)\n",
    "        test_summary_writer = tf.summary.FileWriter(test_logdir)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.exists(flags.ckdir) and tf.train.checkpoint_exists(\n",
    "                flags.ckdir):\n",
    "            latest_check_point = tf.train.latest_checkpoint(flags.ckdir)\n",
    "            saver.restore(sess, latest_check_point)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                os.rmdir(flags.ckdir)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            os.mkdir(flags.ckdir)\n",
    "\n",
    "        try:\n",
    "            global_step = tf.train.get_global_step(sess.graph)\n",
    "\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "            for epoch in range(flags.epochs):\n",
    "\n",
    "                for step in range(0, n_train, flags.batch_size):\n",
    "\n",
    "                    sess.run(training_init_op)\n",
    "\n",
    "                    _, step_iou, step_summary, global_step_value = sess.run(\n",
    "                        [train_op, IOU_op, summary_op, global_step])\n",
    "\n",
    "                    train_summary_writer.add_summary(step_summary,\n",
    "                                                     global_step_value)\n",
    "\n",
    "                '''\n",
    "                total_iou = 0\n",
    "                for step in range(0, n_test, flags.batch_size):\n",
    "                    X_test, y_test = sess.run([X_test_op, y_test_op])\n",
    "                    step_iou, step_summary = sess.run(\n",
    "                        [IOU_op, summary_op],\n",
    "                        feed_dict={X: X_test,\n",
    "                                   y: y_test,\n",
    "                                   mode: False})\n",
    "\n",
    "                    total_iou += step_iou * X_test.shape[0]\n",
    "\n",
    "                    test_summary_writer.add_summary(step_summary,\n",
    "                                                    (epoch + 1) * (step + 1))\n",
    "                '''\n",
    "\n",
    "            saver.save(sess, \"{}/model.ckpt\".format(flags.ckdir))\n",
    "\n",
    "        finally:\n",
    "            saver.save(sess, \"{}/model.ckpt\".format(flags.ckdir))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags = read_flags()\n",
    "    main(flags)\n",
    "    \n",
    "\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "data = data[3,:,:,0]\n",
    "label = label[3,:,:,0]\n",
    " \n",
    "\n",
    "fig, ax = plt.subplots(1,2, sharey=True, figsize=(8,4))\n",
    "\n",
    "ax[0].imshow(data, aspect=\"auto\")\n",
    "ax[1].imshow(label, aspect=\"auto\")\n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = range(0,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10, 2)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpy3",
   "language": "python",
   "name": "mlpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
